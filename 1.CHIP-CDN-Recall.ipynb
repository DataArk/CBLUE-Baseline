{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26ed0df-8358-4311-979e-7dee59f931cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0507110-587b-4b81-a6a1-746cbcc04fcf",
   "metadata": {},
   "source": [
    "### 一、数据读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2239d63-b1ad-4b54-a26c-b5b73e282ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_json('../data/source_datasets/CHIP-CDN/CHIP-CDN_train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c511823-f6b2-4952-94be-2d950cf3a674",
   "metadata": {},
   "outputs": [],
   "source": [
    "icd_df = pd.read_csv('../data/source_datasets/CHIP-CDN/国际疾病分类 ICD-10北京临床版v601.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b195ca79-34d3-4cd7-b4c0-0e49d561a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict = defaultdict(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e151ee-4bb9-4470-8492-386aed4ea303",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _text in icd_df['name']:\n",
    "    map_dict[_text].add(_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afa36e7-0636-48dc-b19d-fedada6df796",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _text in train_df['normalized_result']:\n",
    "    for _label in _text.split('##'):\n",
    "        map_dict[_label].add(_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567eccb7-7af3-4ad0-a955-73b5e247ec84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _text, _labels in zip(train_df['text'], train_df['normalized_result']):\n",
    "    for _label in _labels.split('##'):\n",
    "        map_dict[_text].add(_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762d71be-e3b8-431b-89a7-7c35768ef0d3",
   "metadata": {},
   "source": [
    "### 二、召回模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eb28e3-9076-40a1-a12b-43fd84d6af6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "from six import iteritems\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class BM25(object):\n",
    "    \"\"\"\n",
    "    BM25模型\n",
    "\n",
    "    Args:\n",
    "        corpus (:obj:`list`):\n",
    "            检索的语料\n",
    "        k1 (:obj:`float`, optional, defaults to 1.5):\n",
    "            取正值的调优参数，用于文档中的词项频率进行缩放控制\n",
    "        b (:obj:`float`, optional, defaults to 0.75):\n",
    "            0到1之间的参数，决定文档长度的缩放程度，b=1表示基于文档长度对词项权重进行完全的缩放，b=0表示归一化时不考虑文档长度因素\n",
    "        epsilon (:obj:`float`, optional, defaults to 0.25):\n",
    "            idf的下限值\n",
    "        tokenizer (:obj:`object`, optional, defaults to None):\n",
    "            分词器，用于对文档进行分词操作，默认为None，按字颗粒对文档进行分词\n",
    "        is_retain_docs (:obj:`bool`, optional, defaults to False):\n",
    "            是否保持原始文档\n",
    "\n",
    "    Reference:\n",
    "        [1] https://github.com/RaRe-Technologies/gensim/blob/3.8.3/gensim/summarization/bm25.py\n",
    "    \"\"\"  # noqa: ignore flake8\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        corpus,\n",
    "        k1=1.5,\n",
    "        b=0.75,\n",
    "        epsilon=0.25,\n",
    "        tokenizer=None,\n",
    "        is_retain_docs=False\n",
    "    ):\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        self.docs = None\n",
    "        self.corpus_size = 0\n",
    "        self.avgdl = 0\n",
    "        self.doc_freqs = []\n",
    "        self.idf = {}\n",
    "        self.doc_len = []\n",
    "\n",
    "        if is_retain_docs:\n",
    "            self.docs = copy.deepcopy(corpus)\n",
    "\n",
    "        if tokenizer:\n",
    "            corpus = [self.tokenizer.tokenize(document) for document in corpus]\n",
    "        else:\n",
    "            corpus = [list(document) for document in corpus]\n",
    "\n",
    "        self._initialize(corpus)\n",
    "\n",
    "    def _initialize(self, corpus):\n",
    "        \"\"\"Calculates frequencies of terms in documents and in corpus. Also computes inverse document frequencies.\"\"\"\n",
    "        nd = {}  # word -> number of documents with word\n",
    "        num_doc = 0\n",
    "        for document in corpus:                        \n",
    "            self.corpus_size += 1\n",
    "            self.doc_len.append(len(document))\n",
    "            num_doc += len(document)\n",
    "\n",
    "            frequencies = {}\n",
    "            for word in document:\n",
    "                if word not in frequencies:\n",
    "                    frequencies[word] = 0\n",
    "                frequencies[word] += 1\n",
    "            self.doc_freqs.append(frequencies)\n",
    "\n",
    "            for word, freq in iteritems(frequencies):\n",
    "                if word not in nd:\n",
    "                    nd[word] = 0\n",
    "                nd[word] += 1\n",
    "\n",
    "        self.avgdl = float(num_doc) / self.corpus_size\n",
    "\n",
    "        idf_sum = 0\n",
    "        negative_idfs = []\n",
    "        for word, freq in iteritems(nd):\n",
    "            idf = math.log(self.corpus_size - freq + 0.5) - math.log(freq + 0.5)\n",
    "            self.idf[word] = idf\n",
    "            idf_sum += idf\n",
    "            if idf < 0:\n",
    "                negative_idfs.append(word)\n",
    "        self.average_idf = float(idf_sum) / len(self.idf)\n",
    "\n",
    "        if self.average_idf < 0:\n",
    "            logger.warning(\n",
    "                'Average inverse document frequency is less than zero. Your corpus of {} documents'\n",
    "                ' is either too small or it does not originate from natural text. BM25 may produce'\n",
    "                ' unintuitive results.'.format(self.corpus_size)\n",
    "            )\n",
    "\n",
    "        eps = self.epsilon * self.average_idf\n",
    "        for word in negative_idfs:\n",
    "            self.idf[word] = eps\n",
    "\n",
    "    def get_score(self, query, index):\n",
    "        score = 0.0\n",
    "        doc_freqs = self.doc_freqs[index]\n",
    "        numerator_constant = self.k1 + 1\n",
    "        denominator_constant = self.k1 * (1 - self.b + self.b * self.doc_len[index] / self.avgdl)\n",
    "        for word in query:\n",
    "            if word in doc_freqs:\n",
    "                df = self.doc_freqs[index][word]\n",
    "                idf = self.idf[word]\n",
    "                score += (idf * df * numerator_constant) / (df + denominator_constant)\n",
    "        return score\n",
    "\n",
    "    def get_scores(self, query):\n",
    "        scores = [self.get_score(query, index) for index in range(self.corpus_size)]\n",
    "        return scores\n",
    "\n",
    "    def recall(self, query, topk=5):\n",
    "        scores = self.get_scores(query)\n",
    "        indexs = np.argsort(scores)[::-1][:topk]\n",
    "\n",
    "        if self.docs is None:\n",
    "            return [[i, scores[i]] for i in indexs]\n",
    "        else:\n",
    "            return [[self.docs[i], scores[i]] for i in indexs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf8d662-1a25-405e-b14d-8c8857481199",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_model = BM25([_text for _text, _ in map_dict.items()], is_retain_docs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6810d2-f956-4127-a781-2bd703b14a83",
   "metadata": {},
   "source": [
    "### 三、召回率评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf74b6a-ce12-4e65-874e-9f10a0fa315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data_df = pd.read_json('../data/source_datasets/CHIP-CDN/CHIP-CDN_dev.json')\n",
    "\n",
    "a_label = []\n",
    "new_train_data = []\n",
    "recall_ = 0 \n",
    "query_counter = 0\n",
    "miss_list = []\n",
    "\n",
    "for text_, normalized_result_ in tqdm(zip(dev_data_df['text'], dev_data_df['normalized_result'])):\n",
    "    query_counter += 1\n",
    "    \n",
    "    result = set([_result for _results in bm25_model.recall(text_, topk=200) for _result in map_dict[_results[0]]])\n",
    "            \n",
    "    if len(set(normalized_result_.split('##')) & result) != len(set(normalized_result_.split('##'))):\n",
    "        miss_list.append([text_, normalized_result_])\n",
    "        continue\n",
    "        \n",
    "    recall_ += 1\n",
    "    \n",
    "print('召回率为： ', recall_/query_counter)\n",
    "\n",
    "# 召回率为：  0.9135"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8457df2e-b802-4d94-b4b3-fa353741af03",
   "metadata": {},
   "source": [
    "### 四、模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbf3485-df33-472a-9d80-a11db74018a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../checkpoint/recall/bm25_model.pkl', \"wb\") as f:\n",
    "    pickle.dump(bm25_model, f)\n",
    "    \n",
    "with open('../checkpoint/recall/map_dict.pkl', \"wb\") as f:\n",
    "    pickle.dump(map_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
